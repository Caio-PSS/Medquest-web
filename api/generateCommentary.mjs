/**
 * @typedef {import('@vercel/node').VercelRequest} VercelRequest
 * @typedef {import('@vercel/node').VercelResponse} VercelResponse
 */

import { RateLimiterMemory } from "rate-limiter-flexible";
import OpenAI from "openai";

// Cria limitadores de requisi√ß√£o
const rateLimiterMinute = new RateLimiterMemory({ points: 10, duration: 60 }); // 10 req/min
const rateLimiterDay = new RateLimiterMemory({ points: 50, duration: 86400 }); // 50 req/dia

let concurrentRequests = 0;
const maxConcurrentRequests = 2;

/**
 * @param {VercelRequest} req
 * @param {VercelResponse} res
 */
export default async function handler(req, res) {
  if (req.method !== "POST") {
    return res.status(405).json({ error: "M√©todo n√£o permitido" });
  }

  /** @type {string} */
  const ip = req.headers["x-forwarded-for"] || req.socket.remoteAddress || "";

  try {
    // Aplica limite de requisi√ß√µes
    await rateLimiterMinute.consume(ip);
    await rateLimiterDay.consume(ip);

    // Verifica requisi√ß√µes concorrentes
    if (concurrentRequests >= maxConcurrentRequests) {
      return res.status(429).json({ error: "Muitas requisi√ß√µes concorrentes. Tente novamente." });
    }
    concurrentRequests++;

    // Recebe os dados da requisi√ß√£o (agora incluindo user_id)
    const { sessionStats, user_id } = req.body;
    if (!sessionStats || !user_id) {
      return res.status(400).json({ error: "Par√¢metros ausentes" });
    }
    const { wrongComments = [], correctComments = [] } = sessionStats;

    // Monta o prompt para IA, incluindo detalhes das estat√≠sticas e quest√µes
    const prompt = `**Atue como um tutor especialista em provas de resid√™ncia m√©dica** üîç

1. **An√°lise Geral** (1-2 linhas no m√°ximo):
   - "${sessionStats.correct} acertos vs ${sessionStats.incorrect} erros: [Destaque principal performance]."
   
2. **Raio-X dos Erros** (foco nos ${sessionStats.incorrect} erros):
   ${wrongComments.join("\n\n")}
   ‚ñ∏ Identifique os principais padr√µes nas quest√µes que o estudante errou acima:
   - **Padr√£o**: [Tema] + Motivo (ex: "Confundiu mecanismos fisiopatol√≥gicos? Interpretou exame incorretamente?")
   - **Corre√ß√£o**: A√ß√£o espec√≠fica (ex: "Revisar fluxograma de diagn√≥stico para X")
   - **Impacto**: Como esse erro prejudica na pr√°tica cl√≠nica real?
   
3. **Plano de Revis√£o** (baseado nos erros por t√≥picos, indica quais os assuntos estudar por ordem de prioridade):

Dados-chave:  
‚è≥ Tempo m√©dio: ${(sessionStats.totalTime / sessionStats.totalQuestions).toFixed(1)}s/q  
üìä Taxa de acerto: ${((sessionStats.correct / sessionStats.totalQuestions) * 100).toFixed(1)}%  
üî¥ Maior erro: [√Årea com mais erros]`;

    // Inicializa OpenAI
    const token = process.env.GITHUB_TOKEN;
    if (!token) {
      throw new Error("Token n√£o configurado");
    }
    const client = new OpenAI({ baseURL: "https://models.inference.ai.azure.com", apiKey: token });

    // Envia requisi√ß√£o para OpenAI
    const response = await client.chat.completions.create({
      messages: [
        { role: "system", content: "Voc√™ √© um Coach de quest√µes de resid√™ncia m√©dica." },
        { role: "user", content: prompt },
      ],
      model: "gpt-4o",
      temperature: 1,
      max_tokens: 4000,
      top_p: 1,
    });

    const commentary = response.choices[0].message.content;

    // Envia o coment√°rio gerado para a API de feedbacks para armazenar no banco
    const feedbackApiUrl =
      process.env.FEEDBACK_API_URL ||
      "https://medquest-floral-log-224.fly.dev/api/feedbacks";
    const feedbackPayload = {
      feedback_text: commentary,
      feedback_date: new Date().toISOString(),
      user_id: user_id,
    };
    const feedbackPostResponse = await fetch(feedbackApiUrl, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify(feedbackPayload),
    });

    if (!feedbackPostResponse.ok) {
      console.warn("Falha ao enviar feedback para o banco de dados");
    }

    return res.status(200).json({ commentary });
  } catch (error) {
    console.error("Erro na API de coment√°rio:", error);
    return res.status(500).json({ error: error.message });
  } finally {
    concurrentRequests = Math.max(0, concurrentRequests - 1);
  }
}
